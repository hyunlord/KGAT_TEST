# KGAT 멀티 GPU 학습 설정

defaults:
  - config
  - _self_

# 데이터 설정 - 멀티 GPU를 위한 더 큰 배치 크기
data:
  batch_size: 4096  # 1024 * 4 GPU
  num_workers: 16  # GPU당 4개 워커

# 멀티 GPU를 위한 학습 설정
training:
  accelerator: gpu
  devices: -1  # 모든 GPU 사용
  strategy: ddp  # 분산 데이터 병렬
  precision: 16  # 혼합 정밀도로 더 나은 성능
  
  # 멀티 GPU를 위한 배치 정규화 동기화
  sync_batchnorm: true
  
  # 최적 배치 크기 찾기 (선택사항)
  auto_scale_batch_size: false
  
  # 메모리 문제 시 그래디언트 누적 사용
  accumulate_grad_batches: 1
  
  # 멀티 GPU 설정에서 더 자주 검증
  check_val_every_n_epoch: 2
  
  # DDP 특정 설정 (PyTorch Lightning 2.0에서는 자동 처리됨)