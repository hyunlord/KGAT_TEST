# KGAT Training Configuration

defaults:
  - _self_

# Data configuration
data:
  data_dir: ${oc.env:DATA_DIR,data/amazon-book}  # Can override with DATA_DIR env var
  dataset: amazon-book  # Options: amazon-book, last-fm, yelp2018
  batch_size: 1024
  num_workers: 4
  neg_sample_size: 1

# Model configuration
model:
  embed_dim: 64
  layer_dims: [32, 16]  # Dimensions for each KGAT layer
  dropout: 0.1
  aggregator: bi-interaction  # Options: bi-interaction, sum, concat
  reg_weight: 1e-5
  lr: 0.001

# Training configuration
training:
  max_epochs: 1000
  early_stopping_patience: 20
  seed: 42
  accelerator: auto  # auto, gpu, cpu
  devices: 1  # Number of GPUs to use (1 for single, -1 for all available)
  strategy: auto  # auto, ddp, ddp_spawn, deepspeed, etc.
  precision: 16  # 16 for mixed precision, 32 for full precision
  gradient_clip_val: 5.0
  accumulate_grad_batches: 1
  check_val_every_n_epoch: 5
  log_every_n_steps: 100
  log_dir: logs/
  model_save_dir: models/

# Experiment tracking
experiment:
  name: kgat_baseline
  tags: [kgat, recommendation]
  description: "KGAT baseline training on ${data.dataset}"